{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73650c01-47e3-49b2-9207-04f0ce6eca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import base64\n",
    "import pypdfium2 as pdfium\n",
    "from openai import OpenAI\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "api_url = 'https://www.chatmol.org/ollama/api/generate'\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        \n",
    "# LLM_CLIENT\n",
    "def get_llm_client(provider):\n",
    "    # OpenAI client\n",
    "    if (provider == \"OpenAI\"):\n",
    "        openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "        client = OpenAI(api_key=openai_api_key)\n",
    "    # DeepSeek client\n",
    "    elif (provider == \"DeepSeek\"):\n",
    "        ds_api_key = os.environ[\"DS_API_KEY\"]\n",
    "        # model: deepseek-chat, 128k context window size, 8k max output tokens\n",
    "        client = OpenAI(api_key=ds_api_key, base_url=\"https://api.deepseek.com\")\n",
    "    # Ollama client\n",
    "    elif (provider == \"Ollama\"):\n",
    "        # Using OpenAI interface example\n",
    "        client = OpenAI(\n",
    "            base_url = 'https://www.chatmol.org/ollama/v1/',\n",
    "            #base_url = 'http://100.89.180.132:11434/v1/',\n",
    "            api_key='ollama',  # required but ignored\n",
    "        )\n",
    "    else:\n",
    "        print(\"Unknown LLM provider\")\n",
    "        client = None\n",
    "    return client\n",
    "\n",
    "#OpenAI client\n",
    "# client = get_llm_client(provider=\"OpenAI\")\n",
    "# client = get_llm_client(provider=\"DeepSeek\")\n",
    "# client = get_llm_client(provider=\"Ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9836eca2-8e22-4262-8354-e26f67988c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_headings(doc_md, llm_client, llm_model):\n",
    "    # Create the data payload\n",
    "    prompt = \"\"\"In the following markdown text, all the headers are on the same level. The top level headers are sections. Some sections may have\n",
    "    sub-sections or even sub-sub-sections. Please set the header levels correctly according to the content structures. For simplicity in your \n",
    "    output, you can only response with all headers. Please consider the following rules:\n",
    "    \n",
    "    1. Let's start from level 2, like: ## <seciton_header>\n",
    "    2. If the section header has a number, please also keep the number.\n",
    "    3. Please don't add anything (such as level) that is not in the original headers. \n",
    "    \"\"\"\n",
    "    max_tokens = 2048\n",
    "    responses = llm_client.chat.completions.create(\n",
    "        model = llm_model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\",\"content\": prompt},\n",
    "            {\"role\": \"user\",\"content\": f\"Here is the current markdown text:\\n\\n{doc_md}\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please export correct markdow headings, each per line.\"},\n",
    "        ],\n",
    "        temperature = 0.0,\n",
    "        max_tokens = max_tokens,\n",
    "    )\n",
    "\n",
    "    new_headings = responses.choices[0].message.content\n",
    "    return new_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd6bc7c-95ae-4160-8156-d230acc59a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_headings(original_markdown, correct_headings):\n",
    "    # Split headers into a list\n",
    "    correct_heading_list = correct_headings.strip().split('\\n')\n",
    "    \n",
    "    # Generate a mapping of old to new headers\n",
    "    header_mapping = {}\n",
    "    \n",
    "    for new_header in correct_heading_list:\n",
    "        # Extract the header text without the markdown levels\n",
    "        header_text = new_header.lstrip('# ').strip()\n",
    "        # Create a regex to find headers with varying levels\n",
    "        regex = re.compile(r'^(#{1,6}\\s*)' + re.escape(header_text) + r'$', re.MULTILINE)\n",
    "        # Replace all occurrences with the correct level\n",
    "        header_mapping[regex] = new_header\n",
    "    \n",
    "    # Replace headers in the original markdown\n",
    "    updated_markdown = original_markdown\n",
    "    for pattern, replacement in header_mapping.items():\n",
    "        updated_markdown = pattern.sub(replacement, updated_markdown)\n",
    "    \n",
    "    return updated_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7443702-ed1d-4853-9149-dcc153ec82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docling_pdf_parser(pdf_source):\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(pdf_source)\n",
    "    print(\"Done with docling convert\")\n",
    "    raw_md = result.document.export_to_markdown()\n",
    "    return raw_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec74def-1d49-408d-b32b-10ff5a77c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Parser: convert PDF into markdown format using visual LLMs\n",
    "def llm_pdf_parser(pdf_file_path, client, model):\n",
    "    prompt = \"\"\"\n",
    "    You are an expert to convert a PDF file of a scientific paper into markdown text. This markdown text from the PDF should match the structure of the the \n",
    "    content in PDF. Only export pure markdown and nothing else. Do not explain the output. All headerings will start with ##, ###, ####, and so on. \n",
    "\n",
    "    A scientific paper usually includes a title of the paper, a list of authors and their affiliations. Please extract all of them\n",
    "\n",
    "    Don't add any extra headings if not in the original PDF. For example, don't add a heading of continuation. \n",
    "\n",
    "    Don't add extra marks in your output, such as '```markdown'!\n",
    "\n",
    "    Don't include page numbers in the markdown, don't use page numbers as markdown headings.\n",
    "\n",
    "    If you see a table in PDF, convert it into a markdown table. If there is a table title, put the table content immediately after the table \n",
    "    title. If there are notes of the table, also put the notes immediately after the table without blank line. \n",
    "    \n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(pdf_file_path)\n",
    "    pages = pdfium.PdfDocument(pdf_file_path)\n",
    "    n_pages = len(pages)\n",
    "    images_b64 = []\n",
    "    n_dpi = 108\n",
    "    max_tokens = 2048\n",
    "\n",
    "    # Have some overlap \n",
    "    windows = 5\n",
    "    batch_size = 1\n",
    "    n_batch = int(n_pages/batch_size)\n",
    "    if (n_pages > n_batch*batch_size):\n",
    "        n_batch += 1\n",
    "\n",
    "    pre_batch_text = ''\n",
    "    page_counter = 0\n",
    "    image_contents = []\n",
    "    token_usage = 0\n",
    "\n",
    "    md_text = \"\"\n",
    "\n",
    "    for k in range(n_batch):\n",
    "        nstart = k*batch_size\n",
    "        nend = nstart + batch_size\n",
    "        if (nend > n_pages):\n",
    "            nend = n_pages\n",
    "        current_batch_text = \"\"\n",
    "        image_contents = []\n",
    "        for i in range(nstart, nend):\n",
    "            page = pages[i]\n",
    "            page_counter += 1\n",
    "            p_number = i+1\n",
    "            image = page.render(scale = n_dpi/72).to_pil()\n",
    "            image.save('tmp_image.jpeg',\"JPEG\")\n",
    "            b64_image = encode_image('tmp_image.jpeg')\n",
    "            image_item = [{\"type\": \"text\",\"text\": f\"This is page {p_number}\"},\n",
    "                          {\"type\": \"image_url\", \"image_url\": {\n",
    "                              \"url\": f\"data:image/png;base64,{b64_image}\"}\n",
    "                          }]\n",
    "            image_contents += image_item\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": image_contents}]\n",
    "        if (p_number == 1):\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Please extract all text in each page, including the title of the paper, the author list and their contact information\"})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Please extract all text in each page\"})\n",
    "\n",
    "        responses = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            temperature = 0.0,\n",
    "            max_tokens = max_tokens,\n",
    "        )\n",
    "        current_batch_text = responses.choices[0].message.content\n",
    "        print(\"Finish reason\", responses.choices[0].finish_reason)\n",
    "        token_usage += responses.usage.total_tokens\n",
    "\n",
    "        # Check if the generation is done for the current batch\n",
    "        while (response.choices[0].finish_reason != \"stop\"):\n",
    "            responses = client.chat.completions.create(\n",
    "                model = model,\n",
    "                messages = [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": image_contents},\n",
    "                {\"role\": \"user\", \"content\": \"This is the markdown generated from the PDF so far:\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{pre_batch_text + current_batch_text}\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please complete the remaining markdown content.\"},\n",
    "                ],\n",
    "                temperature = 0.0, \n",
    "                max_tokens = max_tokens,\n",
    "            )\n",
    "            md_text2 = responses.choices[0].message.content\n",
    "            current_batch_text += md_text2\n",
    "            token_usage += responses.usage.total_tokens\n",
    "        md_text += current_batch_text + \"\\n\"\n",
    "        pre_batch_text = current_batch_text\n",
    "    return md_text, token_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a29139-6b83-45e0-8783-e022a18d6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_markdown(pdf_source, method='docling', reflection_provider=\"Ollama\", reflection_model=\"llama33-16k:latest\"):\n",
    "    if (method == 'docling'):\n",
    "        raw_md = docling_pdf_parser(pdf_source)\n",
    "    else:\n",
    "        client = get_llm_client(\"OpenAI\")\n",
    "        model = 'gpt-4o'\n",
    "        raw_md, token_usage = llm_pdf_parser(pdf_source, client, model)\n",
    "    # Self-reflection for markdown heading corrections\n",
    "    reflection_client = get_llm_client(reflection_provider)\n",
    "    new_headings = get_correct_headings(raw_md,reflection_client,reflection_model)\n",
    "    print(new_headings)\n",
    "    doc_md = replace_headings(raw_md, new_headings) \n",
    "    return doc_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d102b18-cf5a-469c-88a8-0ac9eb606aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with docling convert\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs\n",
      "## Abstract\n",
      "## 1 Introduction\n",
      "## 2 ChatMol Copilot Architecture\n",
      "### 2.1 Equipped Tools\n",
      "### 2.2 Integration with Microservices\n",
      "### 2.3 Code as Actions and Redis Cache\n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling\n",
      "### 3.1 General Protein Design Task\n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction\n",
      "### 3.3 Molecular docking task\n",
      "### 3.4 Molecule generation and filtering with generated Python code\n",
      "## 4 Discussion and Conclusions\n",
      "## References\n",
      "## A Cases of using ChatMol Copilot\n",
      "### A.1 Protein stability engineering task\n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table\n",
      "## B All tools\n",
      "### B.1 Ligand binding pocket prediction\n",
      "### B.2 Protein structure prediction\n",
      "### B.3 Mutation effect prediction\n",
      "### B.4 Protein structure visualisation\n",
      "### B.5 Docking\n",
      "### B.6 Blind Docking\n",
      "### B.7 Protein sequence design\n",
      "## C Other details of ChatMol Copilot\n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)\n",
      "### C.2 Registry for computational services\n",
      "### C.3 Function Calling and Agentic Approach\n",
      "### C.4 Registered Services\n",
      "### C.5 ChatMol in PyMOL\n",
      "Time =  22.215213775634766\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs\n",
      "\n",
      "Jinyuan Sun 1 , Auston Li 1,2 , Yifan Deng 1 , Jiabo Li 1,2\n",
      "\n",
      "1 ChatMol Team 2 Wecomput Technology Co., Ltd.\n",
      "\n",
      "Correspondence: jinyuansun@chatmol.org; jiaboli@chatmol.org\n",
      "\n",
      "## Abstract\n",
      "\n",
      "Large Language Models (LLMs) like ChatGPT excel at diverse tasks when given explicit instructions, yet they often struggle with specialized domains such as molecular science, lacking in-depth reasoning and sophisticated planning capabilities. To address these limitations, we introduce ChatMol Copilot, a chatbot-like agent specifically engineered for protein design and small molecule computations. ChatMol Copilot employs a multi-level abstraction framework to expand the LLM's capability. At the basic level, it integrates external computational tools through function calls, thus offloading complex tasks and enabling a focus on strategic decision-making. The second level is data abstraction. Large data sets (such as a large number of molecules created by a generative model) are stored in Redis cache, and the redis keys are referenced by LLMs for data sources involved in computation. The third level of abstraction allows the LLM to orchestrate these tools, either directly or via dynamically generated Python executables. Our evaluations demonstrate that ChatMol Copilot can adeptly manage molecular modeling tasks, effectively utilizing a variety of tools as directed. By simplifying access to sophisticated molecular modeling resources, ChatMol Copilot stands to significantly accelerate drug discovery and biotechnological innovation, empowering biochemists with advanced, user-friendly AI capabilities. The open-sourced code is available at https://github.com/ChatMol/ChatMol\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Large Language Models (LLMs) equipped with specialized tools are catalyzing significant advancements across various scientific fields. In chemistry research, platforms like Coscientist (Boiko et al., 2023) and Chemcrow (M. Bran et al., 2024) have revolutionized lab automation and computational tasks. Furthermore, the novel CodeAct approach,\n",
      "\n",
      "which utilizes \"Code as Action,\" leverages the coding prowess of LLMs to automate complex processes (Wang et al., 2024). Similarly, tools such as AlphaFold 3 (Abramson et al., 2024) have achieved remarkable success in predicting protein interactions and structures, underscoring the potential of computational methods in molecular biology.\n",
      "\n",
      "Despite these strides, significant challenges persist in the molecular engineering field, particularly regarding the execution of complex modeling tasks and the interpretation of their outcomes (Greener et al., 2022). These challenges stem from a need for greater automation and a more intuitive interaction with computational tools. In response, we introduce ChatMol Copilot, a dedicated platform that enhances molecular modeling computations. ChatMol Copilot is designed with a multi-level abstraction framework to maximize automation and user-friendliness. At its foundation, it integrates external computational tools via function calls, simplifying the interface to show only inputs, outputs, and functional descriptions, thereby isolating the LLM from complex computational details. The advanced layer of this framework allows the LLM to either orchestrate these tools directly or through dynamically generated Python executables. This paper demonstrates how ChatMol Copilot effectively manages molecular modeling tasks and delivers precise, actionable responses to user inquiries, significantly streamlining the computational workflow in molecular science.\n",
      "\n",
      "## 2 ChatMol Copilot Architecture\n",
      "\n",
      "The ChatMol Copilot is designed around the capabilities of Large Language Models (LLMs). The system architecture aims to optimize workflow efficiency and precision in molecular modeling tasks.\n",
      "\n",
      "Workflow Overview (Figure 1): The process begins with user instructions, which are interpreted by the LLM. This interpretation step determines\n",
      "\n",
      "Figure 1: The general workflow of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "whether the user's request can be directly answered or if it necessitates the use of specialized tools. ChatMol Copilot supports a broad range of molecular modeling applications, encompassing both small molecules (such as pharmaceuticals) and macromolecules (such as proteins and their interactions). In addition to pre-defined tools, the system can create new tools by writing and executing Python code. This significantly expands its capabilities beyond the predefined action space. Data abstraction is employed to alleviate the burden of data processing from LLMs. Besides internal data usage, the system has access to significant biological databases, enabling it to retrieve and utilize publicly available data as needed. As conversations progress, the integration of user demands with the computational capabilities of ChatMol Copilot facilitates the completion of increasingly complex tasks.\n",
      "\n",
      "### 2.1 Equipped Tools\n",
      "\n",
      "Numerous specialized neural networks have been developed for various molecular property prediction tasks (Wu et al., 2018). ChatMol Copilot integrates a range of tools to meet diverse computational needs, enabling comprehensive and efficient analysis.\n",
      "\n",
      "Neural Network-Based Tools: For tools that utilize neural network inference, such as ESMFold (Lin et al., 2023) and ProteinMPNN (Dauparas\n",
      "\n",
      "et al., 2022), we have implemented publicly accessible APIs. This ensures minimal hardware requirements for users.\n",
      "\n",
      "Local Execution Tools: For faster, Python-based tools, execution is handled locally on the user's computer. Examples include RDKit (Landrum et al., 2013) and TM-align (Zhang and Skolnick, 2005). Table 1 lists the primary tools integrated into the system for both small molecule and macromolecule analysis.\n",
      "\n",
      "### 2.2 Integration with Microservices\n",
      "\n",
      "Microservices are a staple in modern cloud computing architectures due to their scalability and modularity. Each microservice operates independently with a well-defined API and service description. In the ChatMol framework, we have developed a generic method for integrating these microservices into the ChatMol toolbox see Table 1.\n",
      "\n",
      "For each microservice in our registry, Python code is generated based on the input parameter descriptions. This code is then wrapped into a standard function call, compiled on-the-fly, and added to our function calling list. As new microservices are registered, the function list is automatically updated, greatly enhancing the toolbox's capabilities while simplifying ongoing maintenance.\n",
      "\n",
      "Figure 2: General protein design task. Text within purple boxes are instructions from users, and text within green boxes are answers given by ChatMol Copilot. Texts colored blue with underlines are hyperlinks for download files. The table and cartoon represented protein are real screen shots from the GUI of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### 2.3 Code as Actions and Redis Cache\n",
      "\n",
      "Expanding the system's capabilities can be achieved through the automatic generation and execution of code, known as CodeAct. In ChatMol Copilot, we implemented a generic Python code executor and a universal data object access mechanism using Redis cache. Code generation can be based on task descriptions and knowledge from documents. Redis cache and generic data object read/write operations in code enabling the LLM to manage tasks and data flow much simpler by referencing data with their keys.\n",
      "\n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling\n",
      "\n",
      "This section showcases four examples demonstrating the wide-ranging capabilities of ChatMol Copilot in molecular modeling tasks. These use cases illustrate how ChatMol Copilot adheres to user instructions, utilizing appropriate tools from its equipped toolkit and microservices to meet the demands of biochemists, from protein modeling to small molecule de novo synthesis.\n",
      "\n",
      "### 3.1 General Protein Design Task\n",
      "\n",
      "Proteins, essential macromolecules in cells, perform various biological functions, including DNA duplication, metabolic reaction catalysis, and cell\n",
      "\n",
      "cycle regulation. They are also pivotal in healthcare as therapeutic agents like insulin and antibodies, and in various industries as catalysts for cleaner energy and chemicals (Huang et al., 2016).\n",
      "\n",
      "A fundamental challenge in protein design is to find a sequence that folds into a desired structure (Dauparas et al., 2022). This task is complicated by epistasis, where residue-residue interactions can lead to misfolding and loss of function. To address this, we utilized ProteinMPNN (Dauparas et al., 2022) for sequence design and ESMFold (Lin et al., 2023) to predict the fold of the designed sequences. The effectiveness of the designs was validated by comparing their structures to the initial templates, with ChatMol Copilot presenting the results in a well-organized table format. Key metrics such as Root Mean Squared Error (RMSD) and TM-score are highlighted to assess the structural integrity of the designed sequences Figure 2.\n",
      "\n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction\n",
      "\n",
      "The prediction of binding affinity between peptides and MHC-II complexes is critical for assessing the immunogenic potential of newly designed proteins (Jensen et al., 2018). In this use case, ChatMol Copilot was tasked with mutating a peptide sequence five times randomly, then calculating and tabulating the binding affinities of these variants\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "The 3D structure of Zearalenone has been generated and saved. You can download it using the following link: Download zearalenone pdb\n",
      "\n",
      "Here are the top 3 results for \"ZHD1O1 from UniProt: Here is table, upper right.\n",
      "\n",
      "The AlphaFold predicted structure for the entry AOAONIXBU7 has been downloaded. You can get it using\n",
      "\n",
      "Dock zearalenone to AOAONIXBU7\n",
      "\n",
      "The blind docking of Zearalenone to AOAONIXBU7 has been completed successfully. The docking results include several modes with various affinities. The docking complex file has been saved. You can download it using the following link: Download docked\\_complex pdb\n",
      "\n",
      "Here is a summary of the\n",
      "\n",
      "Figure 3: Protein ligand docking task.\n",
      "\n",
      "|     |   1.866 |   2.625 |\n",
      "|-----|---------|---------|\n",
      "| 5.5 |   2.58  |   6.112 |\n",
      "| 4.8 |   2.312 |   6.184 |\n",
      "|     |   1.72  |   2.254 |\n",
      "| 4.3 |   2.314 |   5.167 |\n",
      "| 4.2 |   2.033 |   4.984 |\n",
      "|     |   2.399 |   5.293 |\n",
      "| 3.8 |   2.73  |   4.924 |\n",
      "\n",
      "with the HLA-DPA10103-DPB10201 allele. This multi-step process, handled efficiently by a single user prompt, showcases ChatMol Copilot's ability to manage complex, multi-stage computational tasks effectively Figure 4.\n",
      "\n",
      "### 3.3 Molecular docking task\n",
      "\n",
      "In both designing of drugs or enzymes, molecular docking is commonly involved to determine the intermolecular interactions (Meng et al., 2011). A common molecular docking process requires input of: (1) receptor structure, (2) ligand conformer, (3) docking parameters including centre of box and the size of the box. We show that ChatMol Copilot will facilitate this multi-step task by using a set of related tools. With the name of a ligand provided, the copilot used the tool to search for SMILES and another tool to generate a conformer. After downloading the structure file of the receptor from the RCSB PDB database, the docking parameters were automatically determined under the help of the pocket prediction tool. Finally, the docked complex will be presented to the user Figure 3.\n",
      "\n",
      "### 3.4 Molecule generation and filtering with generated Python code\n",
      "\n",
      "Generating novel molecules with desired properties and structures is very important in drug discovery. A recently large molecule generation model SAFE (Noutahi et al., 2024) is open-sourced. There are\n",
      "\n",
      "6 different modes for molecule generation, each is provided as an API service, and all the 6 APIs are integrated into ChatMol. In the following example, 200 molecules are requested to be generated with a common core. The molecules are stored in Redis cache with key 'SuperStructure\\_smiles'. Figure 5.\n",
      "\n",
      "Molecular properties were calculated using a functional call, and the results were stored in Redis cache. To apply filtering with Lipinski's rule of 5 (Lipinski et al., 2012) to the generated molecules a Python function is created by GPT-4o: Figure 6.\n",
      "\n",
      "In this code, the generated molecules with their properties were read from Redis, and the then Lipinski's rule of 5 is applied to remove molecules that violate the rules. The remaining molecules are saved into Redis. At the end of the code, the total number of the resulting molecules and the first 5 samples are returned.\n",
      "\n",
      "## 4 Discussion and Conclusions\n",
      "\n",
      "In this work, we present a practical solution how to leverage large language models to assist molecular design and computation, particularly for proteins. We also propose the architecture with multi-level abstraction so as to achieve a higher level of automation, which combines multiple steps in one shot. The automatic code generation and execution expands the systems capabilities beyond the predefined action space. The data abstraction with Redis\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "cache makes the \"Code as Actions\" (Wang et al., 2024) more practical for molecular modeling and computation. Similar to the basic concept of \"Code as Actions,\" we use LLMs to generate PyMOL commands in ChatMol based on user instructions, performing relatively complex molecular visualization tasks. Closed-source commercial models like GPT-4 and the Claude series can write PyMOL commands with high accuracy based on user instructions. Smaller open-source models, when finetuned with specific instructions, can also perform this task. As the capabilities of relatively smaller LLMs like phi-3 (Abdin et al., 2024) continue to improve, we can expect future open-source, affordable models to replace current commercial models for ChatMol Copilot needs, further democratizing this field. Even though our current experiments are primitive, we believe that the multi-level abstraction approach is a promising direction to achieve even higher intelligent for molecular design and computation.\n",
      "\n",
      "## References\n",
      "\n",
      "Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
      "\n",
      "Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew J Ballard, Joshua Bambrick, et al. 2024. Accurate structure prediction of biomolecular interactions with alphafold 3. Nature , pages 1-3.\n",
      "\n",
      "Daniil A Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. Autonomous chemical research with large language models. Nature , 624(7992):570578.\n",
      "\n",
      "Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Basile IM Wicky, Alexis Courbet, Rob J de Haas, Neville Bethel, et al. 2022. Robust deep learningbased protein sequence design using proteinmpnn. Science , 378(6615):49-56.\n",
      "\n",
      "Warren L DeLano et al. 2002. Pymol: An open-source molecular graphics tool. CCP4 Newsl. Protein Crystallogr , 40(1):82-92.\n",
      "\n",
      "Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In International conference on machine learning , pages 1263-1272. PMLR.\n",
      "\n",
      "Joe G Greener, Shaun M Kandathil, Lewis Moffat, and David T Jones. 2022. A guide to machine learning for biologists. Nature reviews Molecular cell biology , 23(1):40-55.\n",
      "\n",
      "Po-Ssu Huang, Scott E Boyken, and David Baker. 2016. The coming of age of de novo protein design. Nature , 537(7620):320-327.\n",
      "\n",
      "Kamilla Kjaergaard Jensen, Massimo Andreatta, Paolo Marcatili, Søren Buus, Jason A Greenbaum, Zhen Yan, Alessandro Sette, Bjoern Peters, and Morten Nielsen. 2018. Improved methods for predicting peptide binding affinity to mhc class ii molecules. Immunology , 154(3):394-406.\n",
      "\n",
      "Greg Landrum et al. 2013. Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling. Greg Landrum , 8(31.10):5281.\n",
      "\n",
      "Jiabo Li, Tedman Ehlers, Jon Sutter, Shikha VarmaO'Brien, and Johannes Kirchmair. 2007. Caesar: a new conformer generation algorithm based on recursive buildup and local rotational symmetry consideration. Journal of chemical information and modeling , 47(5):1923-1932.\n",
      "\n",
      "Jiabo Li and Roy McWeeny. 2002. Vb2000: Pushing valence bond theory to new limits. International journal of quantum chemistry , 89(4):208-216.\n",
      "\n",
      "Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. 2023. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science , 379(6637):1123-1130.\n",
      "\n",
      "Christopher A Lipinski, Franco Lombardo, Beryl W Dominy, and Paul J Feeney. 2012. Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings. Advanced drug delivery reviews , 64:4-17.\n",
      "\n",
      "Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. 2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence , pages 1-11.\n",
      "\n",
      "Xuan-Yu Meng, Hong-Xing Zhang, Mihaly Mezei, and Meng Cui. 2011. Molecular docking: a powerful approach for structure-based drug discovery. Current computer-aided drug design , 7(2):146-157.\n",
      "\n",
      "Emmanuel Noutahi, Cristian Gabellini, Michael Craig, Jonathan SC Lim, and Prudencio Tossou. 2024. Gotta be safe: a new framework for molecular design. Digital Discovery , 3(4):796-804.\n",
      "\n",
      "Nicholas Rego and David Koes. 2015. 3dmol. js: molecular visualization with webgl. Bioinformatics , 31(8):1322-1324.\n",
      "\n",
      "David Sehnal, Sebastian Bittrich, Mandar Deshpande, Radka Svobodová, Karel Berka, Václav Bazgier, Sameer Velankar, Stephen K Burley, Jaroslav Koˇca,\n",
      "\n",
      "and Alexander S Rose. 2021. Mol* viewer: modern web app for 3d visualization and analysis of large biomolecular structures. Nucleic acids research , 49(W1):W431-W437.\n",
      "\n",
      "Jinyuan Sun, Tong Zhu, Yinglu Cui, and Bian Wu. 2023. Structure-based self-supervised learning enables ultrafast prediction of stability changes upon mutation at the protein universe scale. bioRxiv , pages 202308.\n",
      "\n",
      "Renxiao Wang, Xueliang Fang, Yipin Lu, Chao-Yie Yang, and Shaomeng Wang. 2005. The pdbbind database: methodologies and updates. Journal of medicinal chemistry , 48(12):4111-4119.\n",
      "\n",
      "Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and Heng Ji. 2024. Executable code actions elicit better llm agents. arXiv preprint arXiv:2402.01030 .\n",
      "\n",
      "Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. 2018. Moleculenet: a benchmark for molecular machine learning. Chemical science , 9(2):513-530.\n",
      "\n",
      "Yang Zhang and Jeffrey Skolnick. 2005. Tm-align: a protein structure alignment algorithm based on the tm-score. Nucleic acids research , 33(7):2302-2309.\n",
      "\n",
      "## A Cases of using ChatMol Copilot\n",
      "\n",
      "### A.1 Protein stability engineering task\n",
      "\n",
      "Enzyme stability engineering plays a crucial role in various biotechnological applications by enhancing the resilience of enzymes to environmental conditions and enabling them to maintain their catalytic activity over extended periods. This process involves modifying specific amino acid residues within the enzyme structure to improve its thermal stability, pH tolerance, resistance to proteolytic degradation, and overall performance under varying conditions.\n",
      "\n",
      "In the process copilot performed, it searches the RCSB PDB database for the LinB enzyme and download it. Subsequently, stabilizing mutations are recommended based on the energy values calculated for each mutation in the provided protein structure according users instructions. These mutations represent amino acid substitutions that are predicted to increase the stability of the enzyme. By introducing these mutations, the enzyme's structural integrity can be enhanced, leading to improved enzymatic activity and potential applications in biocatalysis, drug development, and other biotechnological processes.\n",
      "\n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table\n",
      "\n",
      "In this case, the de novo generation method is used to create a set of molecules. A set of molecular properties are computed for each molecule, and the results are collected for all molecules and a table is created. All these steps are accomplished with just one prompt.\n",
      "\n",
      "## B All tools\n",
      "\n",
      "### B.1 Ligand binding pocket prediction\n",
      "\n",
      "A message passing nerual network (Gilmer et al., 2017) based pocket prediction tool was developed named PocketMPNN. Although many pocket prediction methods were available, a residue-level prediction tool was still in the absence. However, it is of significant importance to facilitate the molecular docking process. Therefore, we developed a neural network trained on the PDB-Bind database (Wang et al., 2005) for pocket residue prediction and a publicly available API was provided. We only took this as a demonstration due to it not being computation extensive and still having satisfactory accuracy.\n",
      "\n",
      "### B.2 Protein structure prediction\n",
      "\n",
      "The public API provided by the ESM Metagenomic Atlas was used for structure prediction. The ESMFold is of good prediction accuracy and fast response compared with MSA-based prediction such AlphaFold2. Within the length of 400 aa, this API usually responds within 20 seconds. Additionally, ESMFold's reliance on evolutionary information enables it to handle diverse protein sequences and structural motifs with high fidelity.\n",
      "\n",
      "### B.3 Mutation effect prediction\n",
      "\n",
      "The public API of Pythia (Sun et al., 2023) was used for mutation effect prediction. The Pythia is a ultra fast mutation effect predictor with good accuracy.\n",
      "\n",
      "### B.4 Protein structure visualisation\n",
      "\n",
      "During the conversation, py3Dmol (Rego and Koes, 2015) is used to show a cartoon representation of a protein. For more interactive and general visualisation and interaction, the streamlit plugin of Mol* (Sehnal et al., 2021) was used.\n",
      "\n",
      "Figure 4: Using MHC binding affinity prediction tool\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Figure 5: Using SAFE for molecular generation\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### B.5 Docking\n",
      "\n",
      "The AutoDock Vina is a fast and widely applied docking tool. We implemented a RESTful API to make it adaptable in the form of a function calling for LLM to use this tool.\n",
      "\n",
      "### B.6 Blind Docking\n",
      "\n",
      "During the docking process, it is necessary for the geometric centre of a pocket to be assigned. However, this inspection of a structure can be challenging without an experimentally determined proteinligand complex. Here, we combined the pocket prediction with the Autodock Vina, using the geometric centre of predicted pocket residues as a hint for docking.\n",
      "\n",
      "### B.7 Protein sequence design\n",
      "\n",
      "We use ProteinMPNN for protein sequence design. It is a neural network based on the message passing neural network, trained on protein structure to generate the native protein sequences and has been experimentally verified to be a robust tool. We also implemented a public accessible API for this copilot.\n",
      "\n",
      "## C Other details of ChatMol Copilot\n",
      "\n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)\n",
      "\n",
      "Visualisation is one of the most important components for the interactions between a user and ChatMol system. In ChatMol Copilot, three different visualisation components can be used. In addition to traditional interactions via the mouse, one important new way of using computers is to communicate with human natural language. This is made possible via LLMs, such as ChatGPT. The advantages of the three visualisation components are listed below:\n",
      "\n",
      "PyMOL (DeLano et al., 2002) has high visual quality, and widely adopted by science communities.\n",
      "\n",
      "MolStar (Mol*) serves as a basis for the nextgeneration data delivery and analysis tools for (not only) macromolecular structure data.\n",
      "\n",
      "py3Dmol is a python package can be integrated easily in other python code.\n",
      "\n",
      "We provide three options there so that users have choices according to their personal preferences.\n",
      "\n",
      "### C.2 Registry for computational services\n",
      "\n",
      "To improve the interoperability of various computational services, all backend services are wrapped with FastAPI. For the convenience of usage and management of these services, a simple registry system for all FastAPI services is implemented. The registry itself is also a FastAPI service, which provides registration for new services, a map for finding and query the services, and for load balancing and routing. Each registry record contains a brief description of the service, the service name, the endpoint URL and the description of input/output parameters.\n",
      "\n",
      "### C.3 Function Calling and Agentic Approach\n",
      "\n",
      "Agentic approach is the new trend of workflow automation and more deeply the road map to artificial general intelligence (AGI) as pointed out by Andrew Ng in his very recent talk at here.\n",
      "\n",
      "As our initial approach in this new paradigm, we have implemented tool use and self reflection in our system design. In additional third party tools, all our internal computational tools which are already wrapped into FastAPI calls are further integrated into ChatMol as function calling services that can be orchestrated using LLMs, such as ChatGPT.\n",
      "\n",
      "### C.4 Registered Services\n",
      "\n",
      "Registry This is the first service of the registry system. The main function of this service is to register other services. To register a server, the following information must be provided: service name, a brief description of the service, the URL for the service endpoint, a list of input parameter names, and the description of the parameters. AlphaConf A superfast 3D conformation generation method developed by ChemXAI. The input is a file of molecules in SDF format, and the output is a file of generated 3D conformations. It takes less than 30 minutes to generate conformations for all ChEMBL database molecules on a 16-core linux machine. The conformation quality as measured by the coverage of bioactive conformers is comparable or even better than the best commercially available products, such as Omega or ConfGenX. AlphaConf follows a divide-n-conquer and build-up strategy similar to CAESAR algorithm (Li et al., 2007). A highly efficient 3D conformation storage technology is used to compress storage by factor up to 3 orders of magnitude. 100,000 conformations/second (16 core machine). 142M confs of ChEMBL storage:\n",
      "\n",
      "Figure 6: Python code generated for Lipinski's rule of five\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Table 1: Integrated Tools in ChatMol Copilot\n",
      "\n",
      "| Macromolecules                                                    | Description                       | Small Molecules            | Description                        |\n",
      "|-------------------------------------------------------------------|-----------------------------------|----------------------------|------------------------------------|\n",
      "| PocketMPNN                                                        | Ligand binding pocket prediction  | SAFE                       | Molecule generation                |\n",
      "| ESM Atlas                                                         | Protein structure predic- tion    | generate 3D conforma- tion | 3D conformation by RDKit           |\n",
      "| Pythia                                                            | Mutation effect predic- tion      | get smiles feature         | Calculate features of molecules    |\n",
      "| py3Dmol, Mol*                                                     | Visualizer                        | predict logp from smiles   | Prediction logP for molecules      |\n",
      "| Autodock                                                          | Docking simulation                | smiles similarity          | Compare molecular similarity       |\n",
      "| ProteinMPNN                                                       | Protein sequence de- sign         | AlphaConf                  | Fast conformation gen- eration     |\n",
      "| BAPrediction                                                      | Peptide-MHC-II bind- ing affinity | AlphaShape                 | Shape based virtual screening      |\n",
      "| search rcsb, query uniprot, fetch asked pdb, get smiles from name | Query databases                   | VB2000                     | Ab initio valence bond calculation |\n",
      "\n",
      "## 2.7GB.\n",
      "\n",
      "AlphaShape Shape and pharmacophore based virtual screening with GPU acceleration. 1000,000 molecule shape comparison/second on a 2RTX4090 GPU machine.\n",
      "\n",
      "VB2000 3.0 This is a completely new implementation of early work VB2000 (Li and McWeeny, 2002). A modern ab initial valence bond calculation program. The first version was released in year 2000, and the current version is 3.0. More information of VB2000 from the official website at here.\n",
      "\n",
      "BAPrediction Binding affinity prediction of peptide-MHC-II molecules. The prediction model is trained with the latest data sets, which include both binding affinity data (BA) and eluted ligand binding data. A combination of XGBoost and a novel feature engineering method has been used to improve the prediction accuracy. It provides better results than the published results in literature.\n",
      "\n",
      "Molecule Generation SAFE is a very recently released open-source molecular generation model is used. The model has 87M parameters and is trained with 1.1 billion compounds in SAFE representations. The SAFE model provides 4 modes for molecule generation: 1) DenovoGen ( de novo molecular generation). Random generation of\n",
      "\n",
      "molecules with no constraints. The output is a set of SMILES strings of the generated molecules. The input parameter is the number of molecules to be generated. 2) SuperStructure. In super structure generation, new molecules are generated based on a starting core. A smiles of the starting core need to be provided. 3) MotifExtend. In motif extension, we are interested in generating a molecule containing a given motif as a starting point. The extension point of the motif need to be labelled. 4) LinkerGen. Linker generation for linking two fragments. The smiles of two terminal fragments need to be provided in the inputs.\n",
      "\n",
      "### C.5 ChatMol in PyMOL\n",
      "\n",
      "As an example of \"code as action\" and the utilization of open-source LLMs, we demonstrate a case where LLMs are directly used to generate PyMOL command lines and perform corresponding molecular visualization tasks in PyMOL. This case involves the use of two LLMs: GPT-4o and a fine-tuned Llama-3-8B-instruct. Both models correctly execute the commands \"download 1pga\" and \"remove waters.\" However, GPT-4o produced an incorrect response Figure 7 when handling the command \"color it by secondary structures\".\n",
      "\n",
      "## GPT-4o\n",
      "\n",
      "Figure 7: Performing same task using GPT-4o and fine-tuned llama-3-8b instruct\n",
      "\n",
      "<!-- image -->\n"
     ]
    }
   ],
   "source": [
    "pdf_file = \"2024.langmol-1.7.pdf\"\n",
    "time1 = time.time()\n",
    "doc_md = pdf_to_markdown(pdf_file, 'docling', 'OpenAI', 'gpt-4o')\n",
    "print(\"Time = \", time.time()-time1)\n",
    "print(doc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d925f0-64ba-4bb6-8d44-cb6ddc4db727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with docling convert\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs  \n",
      "## Abstract  \n",
      "## 1 Introduction  \n",
      "## 2 ChatMol Copilot Architecture  \n",
      "### 2.1 Equipped Tools  \n",
      "### 2.2 Integration with Microservices  \n",
      "### 2.3 Code as Actions and Redis Cache  \n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling  \n",
      "### 3.1 General Protein Design Task  \n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction  \n",
      "### 3.3 Molecular docking task  \n",
      "### 3.4 Molecule generation and filtering with generated Python code  \n",
      "## 4 Discussion and Conclusions  \n",
      "## References  \n",
      "## A Cases of using ChatMol Copilot  \n",
      "### A.1 Protein stability engineering task  \n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table  \n",
      "## B All tools  \n",
      "### B.1 Ligand binding pocket prediction  \n",
      "### B.2 Protein structure prediction  \n",
      "### B.3 Mutation effect prediction  \n",
      "### B.4 Protein structure visualisation  \n",
      "### B.5 Docking  \n",
      "### B.6 Blind Docking  \n",
      "### B.7 Protein sequence design  \n",
      "## C Other details of ChatMol Copilot  \n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)  \n",
      "### C.2 Registry for computational services  \n",
      "### C.3 Function Calling and Agentic Approach  \n",
      "### C.4 Registered Services  \n",
      "### C.5 ChatMol in PyMOL\n",
      "Time =  27.233128786087036\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs  \n",
      "\n",
      "Jinyuan Sun 1 , Auston Li 1,2 , Yifan Deng 1 , Jiabo Li 1,2\n",
      "\n",
      "1 ChatMol Team 2 Wecomput Technology Co., Ltd.\n",
      "\n",
      "Correspondence: jinyuansun@chatmol.org; jiaboli@chatmol.org\n",
      "\n",
      "## Abstract  \n",
      "\n",
      "Large Language Models (LLMs) like ChatGPT excel at diverse tasks when given explicit instructions, yet they often struggle with specialized domains such as molecular science, lacking in-depth reasoning and sophisticated planning capabilities. To address these limitations, we introduce ChatMol Copilot, a chatbot-like agent specifically engineered for protein design and small molecule computations. ChatMol Copilot employs a multi-level abstraction framework to expand the LLM's capability. At the basic level, it integrates external computational tools through function calls, thus offloading complex tasks and enabling a focus on strategic decision-making. The second level is data abstraction. Large data sets (such as a large number of molecules created by a generative model) are stored in Redis cache, and the redis keys are referenced by LLMs for data sources involved in computation. The third level of abstraction allows the LLM to orchestrate these tools, either directly or via dynamically generated Python executables. Our evaluations demonstrate that ChatMol Copilot can adeptly manage molecular modeling tasks, effectively utilizing a variety of tools as directed. By simplifying access to sophisticated molecular modeling resources, ChatMol Copilot stands to significantly accelerate drug discovery and biotechnological innovation, empowering biochemists with advanced, user-friendly AI capabilities. The open-sourced code is available at https://github.com/ChatMol/ChatMol\n",
      "\n",
      "## 1 Introduction  \n",
      "\n",
      "Large Language Models (LLMs) equipped with specialized tools are catalyzing significant advancements across various scientific fields. In chemistry research, platforms like Coscientist (Boiko et al., 2023) and Chemcrow (M. Bran et al., 2024) have revolutionized lab automation and computational tasks. Furthermore, the novel CodeAct approach,\n",
      "\n",
      "which utilizes \"Code as Action,\" leverages the coding prowess of LLMs to automate complex processes (Wang et al., 2024). Similarly, tools such as AlphaFold 3 (Abramson et al., 2024) have achieved remarkable success in predicting protein interactions and structures, underscoring the potential of computational methods in molecular biology.\n",
      "\n",
      "Despite these strides, significant challenges persist in the molecular engineering field, particularly regarding the execution of complex modeling tasks and the interpretation of their outcomes (Greener et al., 2022). These challenges stem from a need for greater automation and a more intuitive interaction with computational tools. In response, we introduce ChatMol Copilot, a dedicated platform that enhances molecular modeling computations. ChatMol Copilot is designed with a multi-level abstraction framework to maximize automation and user-friendliness. At its foundation, it integrates external computational tools via function calls, simplifying the interface to show only inputs, outputs, and functional descriptions, thereby isolating the LLM from complex computational details. The advanced layer of this framework allows the LLM to either orchestrate these tools directly or through dynamically generated Python executables. This paper demonstrates how ChatMol Copilot effectively manages molecular modeling tasks and delivers precise, actionable responses to user inquiries, significantly streamlining the computational workflow in molecular science.\n",
      "\n",
      "## 2 ChatMol Copilot Architecture  \n",
      "\n",
      "The ChatMol Copilot is designed around the capabilities of Large Language Models (LLMs). The system architecture aims to optimize workflow efficiency and precision in molecular modeling tasks.\n",
      "\n",
      "Workflow Overview (Figure 1): The process begins with user instructions, which are interpreted by the LLM. This interpretation step determines\n",
      "\n",
      "Figure 1: The general workflow of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "whether the user's request can be directly answered or if it necessitates the use of specialized tools. ChatMol Copilot supports a broad range of molecular modeling applications, encompassing both small molecules (such as pharmaceuticals) and macromolecules (such as proteins and their interactions). In addition to pre-defined tools, the system can create new tools by writing and executing Python code. This significantly expands its capabilities beyond the predefined action space. Data abstraction is employed to alleviate the burden of data processing from LLMs. Besides internal data usage, the system has access to significant biological databases, enabling it to retrieve and utilize publicly available data as needed. As conversations progress, the integration of user demands with the computational capabilities of ChatMol Copilot facilitates the completion of increasingly complex tasks.\n",
      "\n",
      "### 2.1 Equipped Tools  \n",
      "\n",
      "Numerous specialized neural networks have been developed for various molecular property prediction tasks (Wu et al., 2018). ChatMol Copilot integrates a range of tools to meet diverse computational needs, enabling comprehensive and efficient analysis.\n",
      "\n",
      "Neural Network-Based Tools: For tools that utilize neural network inference, such as ESMFold (Lin et al., 2023) and ProteinMPNN (Dauparas\n",
      "\n",
      "et al., 2022), we have implemented publicly accessible APIs. This ensures minimal hardware requirements for users.\n",
      "\n",
      "Local Execution Tools: For faster, Python-based tools, execution is handled locally on the user's computer. Examples include RDKit (Landrum et al., 2013) and TM-align (Zhang and Skolnick, 2005). Table 1 lists the primary tools integrated into the system for both small molecule and macromolecule analysis.\n",
      "\n",
      "### 2.2 Integration with Microservices  \n",
      "\n",
      "Microservices are a staple in modern cloud computing architectures due to their scalability and modularity. Each microservice operates independently with a well-defined API and service description. In the ChatMol framework, we have developed a generic method for integrating these microservices into the ChatMol toolbox see Table 1.\n",
      "\n",
      "For each microservice in our registry, Python code is generated based on the input parameter descriptions. This code is then wrapped into a standard function call, compiled on-the-fly, and added to our function calling list. As new microservices are registered, the function list is automatically updated, greatly enhancing the toolbox's capabilities while simplifying ongoing maintenance.\n",
      "\n",
      "Figure 2: General protein design task. Text within purple boxes are instructions from users, and text within green boxes are answers given by ChatMol Copilot. Texts colored blue with underlines are hyperlinks for download files. The table and cartoon represented protein are real screen shots from the GUI of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### 2.3 Code as Actions and Redis Cache  \n",
      "\n",
      "Expanding the system's capabilities can be achieved through the automatic generation and execution of code, known as CodeAct. In ChatMol Copilot, we implemented a generic Python code executor and a universal data object access mechanism using Redis cache. Code generation can be based on task descriptions and knowledge from documents. Redis cache and generic data object read/write operations in code enabling the LLM to manage tasks and data flow much simpler by referencing data with their keys.\n",
      "\n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling  \n",
      "\n",
      "This section showcases four examples demonstrating the wide-ranging capabilities of ChatMol Copilot in molecular modeling tasks. These use cases illustrate how ChatMol Copilot adheres to user instructions, utilizing appropriate tools from its equipped toolkit and microservices to meet the demands of biochemists, from protein modeling to small molecule de novo synthesis.\n",
      "\n",
      "### 3.1 General Protein Design Task  \n",
      "\n",
      "Proteins, essential macromolecules in cells, perform various biological functions, including DNA duplication, metabolic reaction catalysis, and cell\n",
      "\n",
      "cycle regulation. They are also pivotal in healthcare as therapeutic agents like insulin and antibodies, and in various industries as catalysts for cleaner energy and chemicals (Huang et al., 2016).\n",
      "\n",
      "A fundamental challenge in protein design is to find a sequence that folds into a desired structure (Dauparas et al., 2022). This task is complicated by epistasis, where residue-residue interactions can lead to misfolding and loss of function. To address this, we utilized ProteinMPNN (Dauparas et al., 2022) for sequence design and ESMFold (Lin et al., 2023) to predict the fold of the designed sequences. The effectiveness of the designs was validated by comparing their structures to the initial templates, with ChatMol Copilot presenting the results in a well-organized table format. Key metrics such as Root Mean Squared Error (RMSD) and TM-score are highlighted to assess the structural integrity of the designed sequences Figure 2.\n",
      "\n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction  \n",
      "\n",
      "The prediction of binding affinity between peptides and MHC-II complexes is critical for assessing the immunogenic potential of newly designed proteins (Jensen et al., 2018). In this use case, ChatMol Copilot was tasked with mutating a peptide sequence five times randomly, then calculating and tabulating the binding affinities of these variants\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "The 3D structure of Zearalenone has been generated and saved. You can download it using the following link: Download zearalenone pdb\n",
      "\n",
      "Here are the top 3 results for \"ZHD1O1 from UniProt: Here is table, upper right.\n",
      "\n",
      "The AlphaFold predicted structure for the entry AOAONIXBU7 has been downloaded. You can get it using\n",
      "\n",
      "Dock zearalenone to AOAONIXBU7\n",
      "\n",
      "The blind docking of Zearalenone to AOAONIXBU7 has been completed successfully. The docking results include several modes with various affinities. The docking complex file has been saved. You can download it using the following link: Download docked\\_complex pdb\n",
      "\n",
      "Here is a summary of the\n",
      "\n",
      "Figure 3: Protein ligand docking task.\n",
      "\n",
      "|     |   1.866 |   2.625 |\n",
      "|-----|---------|---------|\n",
      "| 5.5 |   2.58  |   6.112 |\n",
      "| 4.8 |   2.312 |   6.184 |\n",
      "|     |   1.72  |   2.254 |\n",
      "| 4.3 |   2.314 |   5.167 |\n",
      "| 4.2 |   2.033 |   4.984 |\n",
      "|     |   2.399 |   5.293 |\n",
      "| 3.8 |   2.73  |   4.924 |\n",
      "\n",
      "with the HLA-DPA10103-DPB10201 allele. This multi-step process, handled efficiently by a single user prompt, showcases ChatMol Copilot's ability to manage complex, multi-stage computational tasks effectively Figure 4.\n",
      "\n",
      "### 3.3 Molecular docking task  \n",
      "\n",
      "In both designing of drugs or enzymes, molecular docking is commonly involved to determine the intermolecular interactions (Meng et al., 2011). A common molecular docking process requires input of: (1) receptor structure, (2) ligand conformer, (3) docking parameters including centre of box and the size of the box. We show that ChatMol Copilot will facilitate this multi-step task by using a set of related tools. With the name of a ligand provided, the copilot used the tool to search for SMILES and another tool to generate a conformer. After downloading the structure file of the receptor from the RCSB PDB database, the docking parameters were automatically determined under the help of the pocket prediction tool. Finally, the docked complex will be presented to the user Figure 3.\n",
      "\n",
      "### 3.4 Molecule generation and filtering with generated Python code  \n",
      "\n",
      "Generating novel molecules with desired properties and structures is very important in drug discovery. A recently large molecule generation model SAFE (Noutahi et al., 2024) is open-sourced. There are\n",
      "\n",
      "6 different modes for molecule generation, each is provided as an API service, and all the 6 APIs are integrated into ChatMol. In the following example, 200 molecules are requested to be generated with a common core. The molecules are stored in Redis cache with key 'SuperStructure\\_smiles'. Figure 5.\n",
      "\n",
      "Molecular properties were calculated using a functional call, and the results were stored in Redis cache. To apply filtering with Lipinski's rule of 5 (Lipinski et al., 2012) to the generated molecules a Python function is created by GPT-4o: Figure 6.\n",
      "\n",
      "In this code, the generated molecules with their properties were read from Redis, and the then Lipinski's rule of 5 is applied to remove molecules that violate the rules. The remaining molecules are saved into Redis. At the end of the code, the total number of the resulting molecules and the first 5 samples are returned.\n",
      "\n",
      "## 4 Discussion and Conclusions  \n",
      "\n",
      "In this work, we present a practical solution how to leverage large language models to assist molecular design and computation, particularly for proteins. We also propose the architecture with multi-level abstraction so as to achieve a higher level of automation, which combines multiple steps in one shot. The automatic code generation and execution expands the systems capabilities beyond the predefined action space. The data abstraction with Redis\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "cache makes the \"Code as Actions\" (Wang et al., 2024) more practical for molecular modeling and computation. Similar to the basic concept of \"Code as Actions,\" we use LLMs to generate PyMOL commands in ChatMol based on user instructions, performing relatively complex molecular visualization tasks. Closed-source commercial models like GPT-4 and the Claude series can write PyMOL commands with high accuracy based on user instructions. Smaller open-source models, when finetuned with specific instructions, can also perform this task. As the capabilities of relatively smaller LLMs like phi-3 (Abdin et al., 2024) continue to improve, we can expect future open-source, affordable models to replace current commercial models for ChatMol Copilot needs, further democratizing this field. Even though our current experiments are primitive, we believe that the multi-level abstraction approach is a promising direction to achieve even higher intelligent for molecular design and computation.\n",
      "\n",
      "## References  \n",
      "\n",
      "Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
      "\n",
      "Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew J Ballard, Joshua Bambrick, et al. 2024. Accurate structure prediction of biomolecular interactions with alphafold 3. Nature , pages 1-3.\n",
      "\n",
      "Daniil A Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. Autonomous chemical research with large language models. Nature , 624(7992):570578.\n",
      "\n",
      "Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Basile IM Wicky, Alexis Courbet, Rob J de Haas, Neville Bethel, et al. 2022. Robust deep learningbased protein sequence design using proteinmpnn. Science , 378(6615):49-56.\n",
      "\n",
      "Warren L DeLano et al. 2002. Pymol: An open-source molecular graphics tool. CCP4 Newsl. Protein Crystallogr , 40(1):82-92.\n",
      "\n",
      "Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In International conference on machine learning , pages 1263-1272. PMLR.\n",
      "\n",
      "Joe G Greener, Shaun M Kandathil, Lewis Moffat, and David T Jones. 2022. A guide to machine learning for biologists. Nature reviews Molecular cell biology , 23(1):40-55.\n",
      "\n",
      "Po-Ssu Huang, Scott E Boyken, and David Baker. 2016. The coming of age of de novo protein design. Nature , 537(7620):320-327.\n",
      "\n",
      "Kamilla Kjaergaard Jensen, Massimo Andreatta, Paolo Marcatili, Søren Buus, Jason A Greenbaum, Zhen Yan, Alessandro Sette, Bjoern Peters, and Morten Nielsen. 2018. Improved methods for predicting peptide binding affinity to mhc class ii molecules. Immunology , 154(3):394-406.\n",
      "\n",
      "Greg Landrum et al. 2013. Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling. Greg Landrum , 8(31.10):5281.\n",
      "\n",
      "Jiabo Li, Tedman Ehlers, Jon Sutter, Shikha VarmaO'Brien, and Johannes Kirchmair. 2007. Caesar: a new conformer generation algorithm based on recursive buildup and local rotational symmetry consideration. Journal of chemical information and modeling , 47(5):1923-1932.\n",
      "\n",
      "Jiabo Li and Roy McWeeny. 2002. Vb2000: Pushing valence bond theory to new limits. International journal of quantum chemistry , 89(4):208-216.\n",
      "\n",
      "Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. 2023. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science , 379(6637):1123-1130.\n",
      "\n",
      "Christopher A Lipinski, Franco Lombardo, Beryl W Dominy, and Paul J Feeney. 2012. Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings. Advanced drug delivery reviews , 64:4-17.\n",
      "\n",
      "Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. 2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence , pages 1-11.\n",
      "\n",
      "Xuan-Yu Meng, Hong-Xing Zhang, Mihaly Mezei, and Meng Cui. 2011. Molecular docking: a powerful approach for structure-based drug discovery. Current computer-aided drug design , 7(2):146-157.\n",
      "\n",
      "Emmanuel Noutahi, Cristian Gabellini, Michael Craig, Jonathan SC Lim, and Prudencio Tossou. 2024. Gotta be safe: a new framework for molecular design. Digital Discovery , 3(4):796-804.\n",
      "\n",
      "Nicholas Rego and David Koes. 2015. 3dmol. js: molecular visualization with webgl. Bioinformatics , 31(8):1322-1324.\n",
      "\n",
      "David Sehnal, Sebastian Bittrich, Mandar Deshpande, Radka Svobodová, Karel Berka, Václav Bazgier, Sameer Velankar, Stephen K Burley, Jaroslav Koˇca,\n",
      "\n",
      "and Alexander S Rose. 2021. Mol* viewer: modern web app for 3d visualization and analysis of large biomolecular structures. Nucleic acids research , 49(W1):W431-W437.\n",
      "\n",
      "Jinyuan Sun, Tong Zhu, Yinglu Cui, and Bian Wu. 2023. Structure-based self-supervised learning enables ultrafast prediction of stability changes upon mutation at the protein universe scale. bioRxiv , pages 202308.\n",
      "\n",
      "Renxiao Wang, Xueliang Fang, Yipin Lu, Chao-Yie Yang, and Shaomeng Wang. 2005. The pdbbind database: methodologies and updates. Journal of medicinal chemistry , 48(12):4111-4119.\n",
      "\n",
      "Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and Heng Ji. 2024. Executable code actions elicit better llm agents. arXiv preprint arXiv:2402.01030 .\n",
      "\n",
      "Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. 2018. Moleculenet: a benchmark for molecular machine learning. Chemical science , 9(2):513-530.\n",
      "\n",
      "Yang Zhang and Jeffrey Skolnick. 2005. Tm-align: a protein structure alignment algorithm based on the tm-score. Nucleic acids research , 33(7):2302-2309.\n",
      "\n",
      "## A Cases of using ChatMol Copilot  \n",
      "\n",
      "### A.1 Protein stability engineering task  \n",
      "\n",
      "Enzyme stability engineering plays a crucial role in various biotechnological applications by enhancing the resilience of enzymes to environmental conditions and enabling them to maintain their catalytic activity over extended periods. This process involves modifying specific amino acid residues within the enzyme structure to improve its thermal stability, pH tolerance, resistance to proteolytic degradation, and overall performance under varying conditions.\n",
      "\n",
      "In the process copilot performed, it searches the RCSB PDB database for the LinB enzyme and download it. Subsequently, stabilizing mutations are recommended based on the energy values calculated for each mutation in the provided protein structure according users instructions. These mutations represent amino acid substitutions that are predicted to increase the stability of the enzyme. By introducing these mutations, the enzyme's structural integrity can be enhanced, leading to improved enzymatic activity and potential applications in biocatalysis, drug development, and other biotechnological processes.\n",
      "\n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table  \n",
      "\n",
      "In this case, the de novo generation method is used to create a set of molecules. A set of molecular properties are computed for each molecule, and the results are collected for all molecules and a table is created. All these steps are accomplished with just one prompt.\n",
      "\n",
      "## B All tools  \n",
      "\n",
      "### B.1 Ligand binding pocket prediction  \n",
      "\n",
      "A message passing nerual network (Gilmer et al., 2017) based pocket prediction tool was developed named PocketMPNN. Although many pocket prediction methods were available, a residue-level prediction tool was still in the absence. However, it is of significant importance to facilitate the molecular docking process. Therefore, we developed a neural network trained on the PDB-Bind database (Wang et al., 2005) for pocket residue prediction and a publicly available API was provided. We only took this as a demonstration due to it not being computation extensive and still having satisfactory accuracy.\n",
      "\n",
      "### B.2 Protein structure prediction  \n",
      "\n",
      "The public API provided by the ESM Metagenomic Atlas was used for structure prediction. The ESMFold is of good prediction accuracy and fast response compared with MSA-based prediction such AlphaFold2. Within the length of 400 aa, this API usually responds within 20 seconds. Additionally, ESMFold's reliance on evolutionary information enables it to handle diverse protein sequences and structural motifs with high fidelity.\n",
      "\n",
      "### B.3 Mutation effect prediction  \n",
      "\n",
      "The public API of Pythia (Sun et al., 2023) was used for mutation effect prediction. The Pythia is a ultra fast mutation effect predictor with good accuracy.\n",
      "\n",
      "### B.4 Protein structure visualisation  \n",
      "\n",
      "During the conversation, py3Dmol (Rego and Koes, 2015) is used to show a cartoon representation of a protein. For more interactive and general visualisation and interaction, the streamlit plugin of Mol* (Sehnal et al., 2021) was used.\n",
      "\n",
      "Figure 4: Using MHC binding affinity prediction tool\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Figure 5: Using SAFE for molecular generation\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### B.5 Docking  \n",
      "\n",
      "The AutoDock Vina is a fast and widely applied docking tool. We implemented a RESTful API to make it adaptable in the form of a function calling for LLM to use this tool.\n",
      "\n",
      "### B.6 Blind Docking  \n",
      "\n",
      "During the docking process, it is necessary for the geometric centre of a pocket to be assigned. However, this inspection of a structure can be challenging without an experimentally determined proteinligand complex. Here, we combined the pocket prediction with the Autodock Vina, using the geometric centre of predicted pocket residues as a hint for docking.\n",
      "\n",
      "### B.7 Protein sequence design  \n",
      "\n",
      "We use ProteinMPNN for protein sequence design. It is a neural network based on the message passing neural network, trained on protein structure to generate the native protein sequences and has been experimentally verified to be a robust tool. We also implemented a public accessible API for this copilot.\n",
      "\n",
      "## C Other details of ChatMol Copilot  \n",
      "\n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)  \n",
      "\n",
      "Visualisation is one of the most important components for the interactions between a user and ChatMol system. In ChatMol Copilot, three different visualisation components can be used. In addition to traditional interactions via the mouse, one important new way of using computers is to communicate with human natural language. This is made possible via LLMs, such as ChatGPT. The advantages of the three visualisation components are listed below:\n",
      "\n",
      "PyMOL (DeLano et al., 2002) has high visual quality, and widely adopted by science communities.\n",
      "\n",
      "MolStar (Mol*) serves as a basis for the nextgeneration data delivery and analysis tools for (not only) macromolecular structure data.\n",
      "\n",
      "py3Dmol is a python package can be integrated easily in other python code.\n",
      "\n",
      "We provide three options there so that users have choices according to their personal preferences.\n",
      "\n",
      "### C.2 Registry for computational services  \n",
      "\n",
      "To improve the interoperability of various computational services, all backend services are wrapped with FastAPI. For the convenience of usage and management of these services, a simple registry system for all FastAPI services is implemented. The registry itself is also a FastAPI service, which provides registration for new services, a map for finding and query the services, and for load balancing and routing. Each registry record contains a brief description of the service, the service name, the endpoint URL and the description of input/output parameters.\n",
      "\n",
      "### C.3 Function Calling and Agentic Approach  \n",
      "\n",
      "Agentic approach is the new trend of workflow automation and more deeply the road map to artificial general intelligence (AGI) as pointed out by Andrew Ng in his very recent talk at here.\n",
      "\n",
      "As our initial approach in this new paradigm, we have implemented tool use and self reflection in our system design. In additional third party tools, all our internal computational tools which are already wrapped into FastAPI calls are further integrated into ChatMol as function calling services that can be orchestrated using LLMs, such as ChatGPT.\n",
      "\n",
      "### C.4 Registered Services  \n",
      "\n",
      "Registry This is the first service of the registry system. The main function of this service is to register other services. To register a server, the following information must be provided: service name, a brief description of the service, the URL for the service endpoint, a list of input parameter names, and the description of the parameters. AlphaConf A superfast 3D conformation generation method developed by ChemXAI. The input is a file of molecules in SDF format, and the output is a file of generated 3D conformations. It takes less than 30 minutes to generate conformations for all ChEMBL database molecules on a 16-core linux machine. The conformation quality as measured by the coverage of bioactive conformers is comparable or even better than the best commercially available products, such as Omega or ConfGenX. AlphaConf follows a divide-n-conquer and build-up strategy similar to CAESAR algorithm (Li et al., 2007). A highly efficient 3D conformation storage technology is used to compress storage by factor up to 3 orders of magnitude. 100,000 conformations/second (16 core machine). 142M confs of ChEMBL storage:\n",
      "\n",
      "Figure 6: Python code generated for Lipinski's rule of five\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Table 1: Integrated Tools in ChatMol Copilot\n",
      "\n",
      "| Macromolecules                                                    | Description                       | Small Molecules            | Description                        |\n",
      "|-------------------------------------------------------------------|-----------------------------------|----------------------------|------------------------------------|\n",
      "| PocketMPNN                                                        | Ligand binding pocket prediction  | SAFE                       | Molecule generation                |\n",
      "| ESM Atlas                                                         | Protein structure predic- tion    | generate 3D conforma- tion | 3D conformation by RDKit           |\n",
      "| Pythia                                                            | Mutation effect predic- tion      | get smiles feature         | Calculate features of molecules    |\n",
      "| py3Dmol, Mol*                                                     | Visualizer                        | predict logp from smiles   | Prediction logP for molecules      |\n",
      "| Autodock                                                          | Docking simulation                | smiles similarity          | Compare molecular similarity       |\n",
      "| ProteinMPNN                                                       | Protein sequence de- sign         | AlphaConf                  | Fast conformation gen- eration     |\n",
      "| BAPrediction                                                      | Peptide-MHC-II bind- ing affinity | AlphaShape                 | Shape based virtual screening      |\n",
      "| search rcsb, query uniprot, fetch asked pdb, get smiles from name | Query databases                   | VB2000                     | Ab initio valence bond calculation |\n",
      "\n",
      "## 2.7GB.\n",
      "\n",
      "AlphaShape Shape and pharmacophore based virtual screening with GPU acceleration. 1000,000 molecule shape comparison/second on a 2RTX4090 GPU machine.\n",
      "\n",
      "VB2000 3.0 This is a completely new implementation of early work VB2000 (Li and McWeeny, 2002). A modern ab initial valence bond calculation program. The first version was released in year 2000, and the current version is 3.0. More information of VB2000 from the official website at here.\n",
      "\n",
      "BAPrediction Binding affinity prediction of peptide-MHC-II molecules. The prediction model is trained with the latest data sets, which include both binding affinity data (BA) and eluted ligand binding data. A combination of XGBoost and a novel feature engineering method has been used to improve the prediction accuracy. It provides better results than the published results in literature.\n",
      "\n",
      "Molecule Generation SAFE is a very recently released open-source molecular generation model is used. The model has 87M parameters and is trained with 1.1 billion compounds in SAFE representations. The SAFE model provides 4 modes for molecule generation: 1) DenovoGen ( de novo molecular generation). Random generation of\n",
      "\n",
      "molecules with no constraints. The output is a set of SMILES strings of the generated molecules. The input parameter is the number of molecules to be generated. 2) SuperStructure. In super structure generation, new molecules are generated based on a starting core. A smiles of the starting core need to be provided. 3) MotifExtend. In motif extension, we are interested in generating a molecule containing a given motif as a starting point. The extension point of the motif need to be labelled. 4) LinkerGen. Linker generation for linking two fragments. The smiles of two terminal fragments need to be provided in the inputs.\n",
      "\n",
      "### C.5 ChatMol in PyMOL\n",
      "\n",
      "As an example of \"code as action\" and the utilization of open-source LLMs, we demonstrate a case where LLMs are directly used to generate PyMOL command lines and perform corresponding molecular visualization tasks in PyMOL. This case involves the use of two LLMs: GPT-4o and a fine-tuned Llama-3-8B-instruct. Both models correctly execute the commands \"download 1pga\" and \"remove waters.\" However, GPT-4o produced an incorrect response Figure 7 when handling the command \"color it by secondary structures\".\n",
      "\n",
      "## GPT-4o\n",
      "\n",
      "Figure 7: Performing same task using GPT-4o and fine-tuned llama-3-8b instruct\n",
      "\n",
      "<!-- image -->\n"
     ]
    }
   ],
   "source": [
    "#source = \"https://arxiv.org/pdf/2408.09869\"\n",
    "pdf_source = \"https://aclanthology.org/2024.langmol-1.7.pdf\"\n",
    "time1 = time.time()\n",
    "# DeepSeek V3 context window size upto 128k\n",
    "# Output size: \n",
    "doc_md = pdf_to_markdown(pdf_source, 'docling', 'DeepSeek', 'deepseek-chat')\n",
    "print(\"Time = \", time.time()-time1)\n",
    "print(doc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f12ef74-95da-4a4a-bd31-5bdb7673fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/anaconda3/envs/GenAI310/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with docling convert\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs\n",
      "## Abstract\n",
      "## 1 Introduction\n",
      "## 2 ChatMol Copilot Architecture\n",
      "### 2.1 Equipped Tools\n",
      "### 2.2 Integration with Microservices\n",
      "### 2.3 Code as Actions and Redis Cache\n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling\n",
      "### 3.1 General Protein Design Task\n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction\n",
      "### 3.3 Molecular docking task\n",
      "### 3.4 Molecule generation and filtering with generated Python code\n",
      "## 4 Discussion and Conclusions\n",
      "## A Cases of using ChatMol Copilot\n",
      "### A.1 Protein stability engineering task\n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table\n",
      "## B Other details of ChatMol Copilot\n",
      "### B.1 Ligand binding pocket prediction\n",
      "### B.2 Protein structure prediction\n",
      "### B.3 Mutation effect prediction\n",
      "### B.4 Protein structure visualisation\n",
      "### B.5 Docking\n",
      "### B.6 Blind Docking\n",
      "### B.7 Protein sequence design\n",
      "## C Other details of ChatMol Copilot\n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)\n",
      "### C.2 Registry for computational services\n",
      "### C.3 Function Calling and Agentic Approach\n",
      "### C.4 Registered Services\n",
      "### C.5 ChatMol in PyMOL\n",
      "Time =  108.76541423797607\n",
      "## ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs\n",
      "\n",
      "Jinyuan Sun 1 , Auston Li 1,2 , Yifan Deng 1 , Jiabo Li 1,2\n",
      "\n",
      "1 ChatMol Team 2 Wecomput Technology Co., Ltd.\n",
      "\n",
      "Correspondence: jinyuansun@chatmol.org; jiaboli@chatmol.org\n",
      "\n",
      "## Abstract\n",
      "\n",
      "Large Language Models (LLMs) like ChatGPT excel at diverse tasks when given explicit instructions, yet they often struggle with specialized domains such as molecular science, lacking in-depth reasoning and sophisticated planning capabilities. To address these limitations, we introduce ChatMol Copilot, a chatbot-like agent specifically engineered for protein design and small molecule computations. ChatMol Copilot employs a multi-level abstraction framework to expand the LLM's capability. At the basic level, it integrates external computational tools through function calls, thus offloading complex tasks and enabling a focus on strategic decision-making. The second level is data abstraction. Large data sets (such as a large number of molecules created by a generative model) are stored in Redis cache, and the redis keys are referenced by LLMs for data sources involved in computation. The third level of abstraction allows the LLM to orchestrate these tools, either directly or via dynamically generated Python executables. Our evaluations demonstrate that ChatMol Copilot can adeptly manage molecular modeling tasks, effectively utilizing a variety of tools as directed. By simplifying access to sophisticated molecular modeling resources, ChatMol Copilot stands to significantly accelerate drug discovery and biotechnological innovation, empowering biochemists with advanced, user-friendly AI capabilities. The open-sourced code is available at https://github.com/ChatMol/ChatMol\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Large Language Models (LLMs) equipped with specialized tools are catalyzing significant advancements across various scientific fields. In chemistry research, platforms like Coscientist (Boiko et al., 2023) and Chemcrow (M. Bran et al., 2024) have revolutionized lab automation and computational tasks. Furthermore, the novel CodeAct approach,\n",
      "\n",
      "which utilizes \"Code as Action,\" leverages the coding prowess of LLMs to automate complex processes (Wang et al., 2024). Similarly, tools such as AlphaFold 3 (Abramson et al., 2024) have achieved remarkable success in predicting protein interactions and structures, underscoring the potential of computational methods in molecular biology.\n",
      "\n",
      "Despite these strides, significant challenges persist in the molecular engineering field, particularly regarding the execution of complex modeling tasks and the interpretation of their outcomes (Greener et al., 2022). These challenges stem from a need for greater automation and a more intuitive interaction with computational tools. In response, we introduce ChatMol Copilot, a dedicated platform that enhances molecular modeling computations. ChatMol Copilot is designed with a multi-level abstraction framework to maximize automation and user-friendliness. At its foundation, it integrates external computational tools via function calls, simplifying the interface to show only inputs, outputs, and functional descriptions, thereby isolating the LLM from complex computational details. The advanced layer of this framework allows the LLM to either orchestrate these tools directly or through dynamically generated Python executables. This paper demonstrates how ChatMol Copilot effectively manages molecular modeling tasks and delivers precise, actionable responses to user inquiries, significantly streamlining the computational workflow in molecular science.\n",
      "\n",
      "## 2 ChatMol Copilot Architecture\n",
      "\n",
      "The ChatMol Copilot is designed around the capabilities of Large Language Models (LLMs). The system architecture aims to optimize workflow efficiency and precision in molecular modeling tasks.\n",
      "\n",
      "Workflow Overview (Figure 1): The process begins with user instructions, which are interpreted by the LLM. This interpretation step determines\n",
      "\n",
      "Figure 1: The general workflow of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "whether the user's request can be directly answered or if it necessitates the use of specialized tools. ChatMol Copilot supports a broad range of molecular modeling applications, encompassing both small molecules (such as pharmaceuticals) and macromolecules (such as proteins and their interactions). In addition to pre-defined tools, the system can create new tools by writing and executing Python code. This significantly expands its capabilities beyond the predefined action space. Data abstraction is employed to alleviate the burden of data processing from LLMs. Besides internal data usage, the system has access to significant biological databases, enabling it to retrieve and utilize publicly available data as needed. As conversations progress, the integration of user demands with the computational capabilities of ChatMol Copilot facilitates the completion of increasingly complex tasks.\n",
      "\n",
      "### 2.1 Equipped Tools\n",
      "\n",
      "Numerous specialized neural networks have been developed for various molecular property prediction tasks (Wu et al., 2018). ChatMol Copilot integrates a range of tools to meet diverse computational needs, enabling comprehensive and efficient analysis.\n",
      "\n",
      "Neural Network-Based Tools: For tools that utilize neural network inference, such as ESMFold (Lin et al., 2023) and ProteinMPNN (Dauparas\n",
      "\n",
      "et al., 2022), we have implemented publicly accessible APIs. This ensures minimal hardware requirements for users.\n",
      "\n",
      "Local Execution Tools: For faster, Python-based tools, execution is handled locally on the user's computer. Examples include RDKit (Landrum et al., 2013) and TM-align (Zhang and Skolnick, 2005). Table 1 lists the primary tools integrated into the system for both small molecule and macromolecule analysis.\n",
      "\n",
      "### 2.2 Integration with Microservices\n",
      "\n",
      "Microservices are a staple in modern cloud computing architectures due to their scalability and modularity. Each microservice operates independently with a well-defined API and service description. In the ChatMol framework, we have developed a generic method for integrating these microservices into the ChatMol toolbox see Table 1.\n",
      "\n",
      "For each microservice in our registry, Python code is generated based on the input parameter descriptions. This code is then wrapped into a standard function call, compiled on-the-fly, and added to our function calling list. As new microservices are registered, the function list is automatically updated, greatly enhancing the toolbox's capabilities while simplifying ongoing maintenance.\n",
      "\n",
      "Figure 2: General protein design task. Text within purple boxes are instructions from users, and text within green boxes are answers given by ChatMol Copilot. Texts colored blue with underlines are hyperlinks for download files. The table and cartoon represented protein are real screen shots from the GUI of ChatMol Copilot.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### 2.3 Code as Actions and Redis Cache\n",
      "\n",
      "Expanding the system's capabilities can be achieved through the automatic generation and execution of code, known as CodeAct. In ChatMol Copilot, we implemented a generic Python code executor and a universal data object access mechanism using Redis cache. Code generation can be based on task descriptions and knowledge from documents. Redis cache and generic data object read/write operations in code enabling the LLM to manage tasks and data flow much simpler by referencing data with their keys.\n",
      "\n",
      "## 3 Use Cases of ChatMol Copilot for Molecular Modeling\n",
      "\n",
      "This section showcases four examples demonstrating the wide-ranging capabilities of ChatMol Copilot in molecular modeling tasks. These use cases illustrate how ChatMol Copilot adheres to user instructions, utilizing appropriate tools from its equipped toolkit and microservices to meet the demands of biochemists, from protein modeling to small molecule de novo synthesis.\n",
      "\n",
      "### 3.1 General Protein Design Task\n",
      "\n",
      "Proteins, essential macromolecules in cells, perform various biological functions, including DNA duplication, metabolic reaction catalysis, and cell\n",
      "\n",
      "cycle regulation. They are also pivotal in healthcare as therapeutic agents like insulin and antibodies, and in various industries as catalysts for cleaner energy and chemicals (Huang et al., 2016).\n",
      "\n",
      "A fundamental challenge in protein design is to find a sequence that folds into a desired structure (Dauparas et al., 2022). This task is complicated by epistasis, where residue-residue interactions can lead to misfolding and loss of function. To address this, we utilized ProteinMPNN (Dauparas et al., 2022) for sequence design and ESMFold (Lin et al., 2023) to predict the fold of the designed sequences. The effectiveness of the designs was validated by comparing their structures to the initial templates, with ChatMol Copilot presenting the results in a well-organized table format. Key metrics such as Root Mean Squared Error (RMSD) and TM-score are highlighted to assess the structural integrity of the designed sequences Figure 2.\n",
      "\n",
      "### 3.2 Peptide/MHC-II Binding Affinity Prediction\n",
      "\n",
      "The prediction of binding affinity between peptides and MHC-II complexes is critical for assessing the immunogenic potential of newly designed proteins (Jensen et al., 2018). In this use case, ChatMol Copilot was tasked with mutating a peptide sequence five times randomly, then calculating and tabulating the binding affinities of these variants\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "The 3D structure of Zearalenone has been generated and saved. You can download it using the following link: Download zearalenone pdb\n",
      "\n",
      "Here are the top 3 results for \"ZHD1O1 from UniProt: Here is table, upper right.\n",
      "\n",
      "The AlphaFold predicted structure for the entry AOAONIXBU7 has been downloaded. You can get it using\n",
      "\n",
      "Dock zearalenone to AOAONIXBU7\n",
      "\n",
      "The blind docking of Zearalenone to AOAONIXBU7 has been completed successfully. The docking results include several modes with various affinities. The docking complex file has been saved. You can download it using the following link: Download docked\\_complex pdb\n",
      "\n",
      "Here is a summary of the\n",
      "\n",
      "Figure 3: Protein ligand docking task.\n",
      "\n",
      "|     |   1.866 |   2.625 |\n",
      "|-----|---------|---------|\n",
      "| 5.5 |   2.58  |   6.112 |\n",
      "| 4.8 |   2.312 |   6.184 |\n",
      "|     |   1.72  |   2.254 |\n",
      "| 4.3 |   2.314 |   5.167 |\n",
      "| 4.2 |   2.033 |   4.984 |\n",
      "|     |   2.399 |   5.293 |\n",
      "| 3.8 |   2.73  |   4.924 |\n",
      "\n",
      "with the HLA-DPA10103-DPB10201 allele. This multi-step process, handled efficiently by a single user prompt, showcases ChatMol Copilot's ability to manage complex, multi-stage computational tasks effectively Figure 4.\n",
      "\n",
      "### 3.3 Molecular docking task\n",
      "\n",
      "In both designing of drugs or enzymes, molecular docking is commonly involved to determine the intermolecular interactions (Meng et al., 2011). A common molecular docking process requires input of: (1) receptor structure, (2) ligand conformer, (3) docking parameters including centre of box and the size of the box. We show that ChatMol Copilot will facilitate this multi-step task by using a set of related tools. With the name of a ligand provided, the copilot used the tool to search for SMILES and another tool to generate a conformer. After downloading the structure file of the receptor from the RCSB PDB database, the docking parameters were automatically determined under the help of the pocket prediction tool. Finally, the docked complex will be presented to the user Figure 3.\n",
      "\n",
      "### 3.4 Molecule generation and filtering with generated Python code\n",
      "\n",
      "Generating novel molecules with desired properties and structures is very important in drug discovery. A recently large molecule generation model SAFE (Noutahi et al., 2024) is open-sourced. There are\n",
      "\n",
      "6 different modes for molecule generation, each is provided as an API service, and all the 6 APIs are integrated into ChatMol. In the following example, 200 molecules are requested to be generated with a common core. The molecules are stored in Redis cache with key 'SuperStructure\\_smiles'. Figure 5.\n",
      "\n",
      "Molecular properties were calculated using a functional call, and the results were stored in Redis cache. To apply filtering with Lipinski's rule of 5 (Lipinski et al., 2012) to the generated molecules a Python function is created by GPT-4o: Figure 6.\n",
      "\n",
      "In this code, the generated molecules with their properties were read from Redis, and the then Lipinski's rule of 5 is applied to remove molecules that violate the rules. The remaining molecules are saved into Redis. At the end of the code, the total number of the resulting molecules and the first 5 samples are returned.\n",
      "\n",
      "## 4 Discussion and Conclusions\n",
      "\n",
      "In this work, we present a practical solution how to leverage large language models to assist molecular design and computation, particularly for proteins. We also propose the architecture with multi-level abstraction so as to achieve a higher level of automation, which combines multiple steps in one shot. The automatic code generation and execution expands the systems capabilities beyond the predefined action space. The data abstraction with Redis\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "cache makes the \"Code as Actions\" (Wang et al., 2024) more practical for molecular modeling and computation. Similar to the basic concept of \"Code as Actions,\" we use LLMs to generate PyMOL commands in ChatMol based on user instructions, performing relatively complex molecular visualization tasks. Closed-source commercial models like GPT-4 and the Claude series can write PyMOL commands with high accuracy based on user instructions. Smaller open-source models, when finetuned with specific instructions, can also perform this task. As the capabilities of relatively smaller LLMs like phi-3 (Abdin et al., 2024) continue to improve, we can expect future open-source, affordable models to replace current commercial models for ChatMol Copilot needs, further democratizing this field. Even though our current experiments are primitive, we believe that the multi-level abstraction approach is a promising direction to achieve even higher intelligent for molecular design and computation.\n",
      "\n",
      "## References\n",
      "\n",
      "Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
      "\n",
      "Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew J Ballard, Joshua Bambrick, et al. 2024. Accurate structure prediction of biomolecular interactions with alphafold 3. Nature , pages 1-3.\n",
      "\n",
      "Daniil A Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. Autonomous chemical research with large language models. Nature , 624(7992):570578.\n",
      "\n",
      "Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Basile IM Wicky, Alexis Courbet, Rob J de Haas, Neville Bethel, et al. 2022. Robust deep learningbased protein sequence design using proteinmpnn. Science , 378(6615):49-56.\n",
      "\n",
      "Warren L DeLano et al. 2002. Pymol: An open-source molecular graphics tool. CCP4 Newsl. Protein Crystallogr , 40(1):82-92.\n",
      "\n",
      "Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In International conference on machine learning , pages 1263-1272. PMLR.\n",
      "\n",
      "Joe G Greener, Shaun M Kandathil, Lewis Moffat, and David T Jones. 2022. A guide to machine learning for biologists. Nature reviews Molecular cell biology , 23(1):40-55.\n",
      "\n",
      "Po-Ssu Huang, Scott E Boyken, and David Baker. 2016. The coming of age of de novo protein design. Nature , 537(7620):320-327.\n",
      "\n",
      "Kamilla Kjaergaard Jensen, Massimo Andreatta, Paolo Marcatili, Søren Buus, Jason A Greenbaum, Zhen Yan, Alessandro Sette, Bjoern Peters, and Morten Nielsen. 2018. Improved methods for predicting peptide binding affinity to mhc class ii molecules. Immunology , 154(3):394-406.\n",
      "\n",
      "Greg Landrum et al. 2013. Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling. Greg Landrum , 8(31.10):5281.\n",
      "\n",
      "Jiabo Li, Tedman Ehlers, Jon Sutter, Shikha VarmaO'Brien, and Johannes Kirchmair. 2007. Caesar: a new conformer generation algorithm based on recursive buildup and local rotational symmetry consideration. Journal of chemical information and modeling , 47(5):1923-1932.\n",
      "\n",
      "Jiabo Li and Roy McWeeny. 2002. Vb2000: Pushing valence bond theory to new limits. International journal of quantum chemistry , 89(4):208-216.\n",
      "\n",
      "Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. 2023. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science , 379(6637):1123-1130.\n",
      "\n",
      "Christopher A Lipinski, Franco Lombardo, Beryl W Dominy, and Paul J Feeney. 2012. Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings. Advanced drug delivery reviews , 64:4-17.\n",
      "\n",
      "Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. 2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence , pages 1-11.\n",
      "\n",
      "Xuan-Yu Meng, Hong-Xing Zhang, Mihaly Mezei, and Meng Cui. 2011. Molecular docking: a powerful approach for structure-based drug discovery. Current computer-aided drug design , 7(2):146-157.\n",
      "\n",
      "Emmanuel Noutahi, Cristian Gabellini, Michael Craig, Jonathan SC Lim, and Prudencio Tossou. 2024. Gotta be safe: a new framework for molecular design. Digital Discovery , 3(4):796-804.\n",
      "\n",
      "Nicholas Rego and David Koes. 2015. 3dmol. js: molecular visualization with webgl. Bioinformatics , 31(8):1322-1324.\n",
      "\n",
      "David Sehnal, Sebastian Bittrich, Mandar Deshpande, Radka Svobodová, Karel Berka, Václav Bazgier, Sameer Velankar, Stephen K Burley, Jaroslav Koˇca,\n",
      "\n",
      "and Alexander S Rose. 2021. Mol* viewer: modern web app for 3d visualization and analysis of large biomolecular structures. Nucleic acids research , 49(W1):W431-W437.\n",
      "\n",
      "Jinyuan Sun, Tong Zhu, Yinglu Cui, and Bian Wu. 2023. Structure-based self-supervised learning enables ultrafast prediction of stability changes upon mutation at the protein universe scale. bioRxiv , pages 202308.\n",
      "\n",
      "Renxiao Wang, Xueliang Fang, Yipin Lu, Chao-Yie Yang, and Shaomeng Wang. 2005. The pdbbind database: methodologies and updates. Journal of medicinal chemistry , 48(12):4111-4119.\n",
      "\n",
      "Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and Heng Ji. 2024. Executable code actions elicit better llm agents. arXiv preprint arXiv:2402.01030 .\n",
      "\n",
      "Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. 2018. Moleculenet: a benchmark for molecular machine learning. Chemical science , 9(2):513-530.\n",
      "\n",
      "Yang Zhang and Jeffrey Skolnick. 2005. Tm-align: a protein structure alignment algorithm based on the tm-score. Nucleic acids research , 33(7):2302-2309.\n",
      "\n",
      "## A Cases of using ChatMol Copilot\n",
      "\n",
      "### A.1 Protein stability engineering task\n",
      "\n",
      "Enzyme stability engineering plays a crucial role in various biotechnological applications by enhancing the resilience of enzymes to environmental conditions and enabling them to maintain their catalytic activity over extended periods. This process involves modifying specific amino acid residues within the enzyme structure to improve its thermal stability, pH tolerance, resistance to proteolytic degradation, and overall performance under varying conditions.\n",
      "\n",
      "In the process copilot performed, it searches the RCSB PDB database for the LinB enzyme and download it. Subsequently, stabilizing mutations are recommended based on the energy values calculated for each mutation in the provided protein structure according users instructions. These mutations represent amino acid substitutions that are predicted to increase the stability of the enzyme. By introducing these mutations, the enzyme's structural integrity can be enhanced, leading to improved enzymatic activity and potential applications in biocatalysis, drug development, and other biotechnological processes.\n",
      "\n",
      "### A.2 Generate a set of molecules, compute the molecular properties and display the results in a table\n",
      "\n",
      "In this case, the de novo generation method is used to create a set of molecules. A set of molecular properties are computed for each molecule, and the results are collected for all molecules and a table is created. All these steps are accomplished with just one prompt.\n",
      "\n",
      "## B All tools\n",
      "\n",
      "### B.1 Ligand binding pocket prediction\n",
      "\n",
      "A message passing nerual network (Gilmer et al., 2017) based pocket prediction tool was developed named PocketMPNN. Although many pocket prediction methods were available, a residue-level prediction tool was still in the absence. However, it is of significant importance to facilitate the molecular docking process. Therefore, we developed a neural network trained on the PDB-Bind database (Wang et al., 2005) for pocket residue prediction and a publicly available API was provided. We only took this as a demonstration due to it not being computation extensive and still having satisfactory accuracy.\n",
      "\n",
      "### B.2 Protein structure prediction\n",
      "\n",
      "The public API provided by the ESM Metagenomic Atlas was used for structure prediction. The ESMFold is of good prediction accuracy and fast response compared with MSA-based prediction such AlphaFold2. Within the length of 400 aa, this API usually responds within 20 seconds. Additionally, ESMFold's reliance on evolutionary information enables it to handle diverse protein sequences and structural motifs with high fidelity.\n",
      "\n",
      "### B.3 Mutation effect prediction\n",
      "\n",
      "The public API of Pythia (Sun et al., 2023) was used for mutation effect prediction. The Pythia is a ultra fast mutation effect predictor with good accuracy.\n",
      "\n",
      "### B.4 Protein structure visualisation\n",
      "\n",
      "During the conversation, py3Dmol (Rego and Koes, 2015) is used to show a cartoon representation of a protein. For more interactive and general visualisation and interaction, the streamlit plugin of Mol* (Sehnal et al., 2021) was used.\n",
      "\n",
      "Figure 4: Using MHC binding affinity prediction tool\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Figure 5: Using SAFE for molecular generation\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "### B.5 Docking\n",
      "\n",
      "The AutoDock Vina is a fast and widely applied docking tool. We implemented a RESTful API to make it adaptable in the form of a function calling for LLM to use this tool.\n",
      "\n",
      "### B.6 Blind Docking\n",
      "\n",
      "During the docking process, it is necessary for the geometric centre of a pocket to be assigned. However, this inspection of a structure can be challenging without an experimentally determined proteinligand complex. Here, we combined the pocket prediction with the Autodock Vina, using the geometric centre of predicted pocket residues as a hint for docking.\n",
      "\n",
      "### B.7 Protein sequence design\n",
      "\n",
      "We use ProteinMPNN for protein sequence design. It is a neural network based on the message passing neural network, trained on protein structure to generate the native protein sequences and has been experimentally verified to be a robust tool. We also implemented a public accessible API for this copilot.\n",
      "\n",
      "## C Other details of ChatMol Copilot\n",
      "\n",
      "### C.1 Visualisation Components (Mol*, PyMOL and py3Dmol)\n",
      "\n",
      "Visualisation is one of the most important components for the interactions between a user and ChatMol system. In ChatMol Copilot, three different visualisation components can be used. In addition to traditional interactions via the mouse, one important new way of using computers is to communicate with human natural language. This is made possible via LLMs, such as ChatGPT. The advantages of the three visualisation components are listed below:\n",
      "\n",
      "PyMOL (DeLano et al., 2002) has high visual quality, and widely adopted by science communities.\n",
      "\n",
      "MolStar (Mol*) serves as a basis for the nextgeneration data delivery and analysis tools for (not only) macromolecular structure data.\n",
      "\n",
      "py3Dmol is a python package can be integrated easily in other python code.\n",
      "\n",
      "We provide three options there so that users have choices according to their personal preferences.\n",
      "\n",
      "### C.2 Registry for computational services\n",
      "\n",
      "To improve the interoperability of various computational services, all backend services are wrapped with FastAPI. For the convenience of usage and management of these services, a simple registry system for all FastAPI services is implemented. The registry itself is also a FastAPI service, which provides registration for new services, a map for finding and query the services, and for load balancing and routing. Each registry record contains a brief description of the service, the service name, the endpoint URL and the description of input/output parameters.\n",
      "\n",
      "### C.3 Function Calling and Agentic Approach\n",
      "\n",
      "Agentic approach is the new trend of workflow automation and more deeply the road map to artificial general intelligence (AGI) as pointed out by Andrew Ng in his very recent talk at here.\n",
      "\n",
      "As our initial approach in this new paradigm, we have implemented tool use and self reflection in our system design. In additional third party tools, all our internal computational tools which are already wrapped into FastAPI calls are further integrated into ChatMol as function calling services that can be orchestrated using LLMs, such as ChatGPT.\n",
      "\n",
      "### C.4 Registered Services\n",
      "\n",
      "Registry This is the first service of the registry system. The main function of this service is to register other services. To register a server, the following information must be provided: service name, a brief description of the service, the URL for the service endpoint, a list of input parameter names, and the description of the parameters. AlphaConf A superfast 3D conformation generation method developed by ChemXAI. The input is a file of molecules in SDF format, and the output is a file of generated 3D conformations. It takes less than 30 minutes to generate conformations for all ChEMBL database molecules on a 16-core linux machine. The conformation quality as measured by the coverage of bioactive conformers is comparable or even better than the best commercially available products, such as Omega or ConfGenX. AlphaConf follows a divide-n-conquer and build-up strategy similar to CAESAR algorithm (Li et al., 2007). A highly efficient 3D conformation storage technology is used to compress storage by factor up to 3 orders of magnitude. 100,000 conformations/second (16 core machine). 142M confs of ChEMBL storage:\n",
      "\n",
      "Figure 6: Python code generated for Lipinski's rule of five\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Table 1: Integrated Tools in ChatMol Copilot\n",
      "\n",
      "| Macromolecules                                                    | Description                       | Small Molecules            | Description                        |\n",
      "|-------------------------------------------------------------------|-----------------------------------|----------------------------|------------------------------------|\n",
      "| PocketMPNN                                                        | Ligand binding pocket prediction  | SAFE                       | Molecule generation                |\n",
      "| ESM Atlas                                                         | Protein structure predic- tion    | generate 3D conforma- tion | 3D conformation by RDKit           |\n",
      "| Pythia                                                            | Mutation effect predic- tion      | get smiles feature         | Calculate features of molecules    |\n",
      "| py3Dmol, Mol*                                                     | Visualizer                        | predict logp from smiles   | Prediction logP for molecules      |\n",
      "| Autodock                                                          | Docking simulation                | smiles similarity          | Compare molecular similarity       |\n",
      "| ProteinMPNN                                                       | Protein sequence de- sign         | AlphaConf                  | Fast conformation gen- eration     |\n",
      "| BAPrediction                                                      | Peptide-MHC-II bind- ing affinity | AlphaShape                 | Shape based virtual screening      |\n",
      "| search rcsb, query uniprot, fetch asked pdb, get smiles from name | Query databases                   | VB2000                     | Ab initio valence bond calculation |\n",
      "\n",
      "## 2.7GB.\n",
      "\n",
      "AlphaShape Shape and pharmacophore based virtual screening with GPU acceleration. 1000,000 molecule shape comparison/second on a 2RTX4090 GPU machine.\n",
      "\n",
      "VB2000 3.0 This is a completely new implementation of early work VB2000 (Li and McWeeny, 2002). A modern ab initial valence bond calculation program. The first version was released in year 2000, and the current version is 3.0. More information of VB2000 from the official website at here.\n",
      "\n",
      "BAPrediction Binding affinity prediction of peptide-MHC-II molecules. The prediction model is trained with the latest data sets, which include both binding affinity data (BA) and eluted ligand binding data. A combination of XGBoost and a novel feature engineering method has been used to improve the prediction accuracy. It provides better results than the published results in literature.\n",
      "\n",
      "Molecule Generation SAFE is a very recently released open-source molecular generation model is used. The model has 87M parameters and is trained with 1.1 billion compounds in SAFE representations. The SAFE model provides 4 modes for molecule generation: 1) DenovoGen ( de novo molecular generation). Random generation of\n",
      "\n",
      "molecules with no constraints. The output is a set of SMILES strings of the generated molecules. The input parameter is the number of molecules to be generated. 2) SuperStructure. In super structure generation, new molecules are generated based on a starting core. A smiles of the starting core need to be provided. 3) MotifExtend. In motif extension, we are interested in generating a molecule containing a given motif as a starting point. The extension point of the motif need to be labelled. 4) LinkerGen. Linker generation for linking two fragments. The smiles of two terminal fragments need to be provided in the inputs.\n",
      "\n",
      "### C.5 ChatMol in PyMOL\n",
      "\n",
      "As an example of \"code as action\" and the utilization of open-source LLMs, we demonstrate a case where LLMs are directly used to generate PyMOL command lines and perform corresponding molecular visualization tasks in PyMOL. This case involves the use of two LLMs: GPT-4o and a fine-tuned Llama-3-8B-instruct. Both models correctly execute the commands \"download 1pga\" and \"remove waters.\" However, GPT-4o produced an incorrect response Figure 7 when handling the command \"color it by secondary structures\".\n",
      "\n",
      "## GPT-4o\n",
      "\n",
      "Figure 7: Performing same task using GPT-4o and fine-tuned llama-3-8b instruct\n",
      "\n",
      "<!-- image -->\n"
     ]
    }
   ],
   "source": [
    "#source = \"https://arxiv.org/pdf/2408.09869\"\n",
    "pdf_source = \"https://aclanthology.org/2024.langmol-1.7.pdf\"\n",
    "time1 = time.time()\n",
    "# Ollama/llama33-16k: 16k context window size\n",
    "# Output size: \n",
    "doc_md = pdf_to_markdown(pdf_source, 'docling', 'Ollama', 'llama33-16k:latest')\n",
    "print(\"Time = \", time.time()-time1)\n",
    "print(doc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df260564-f9a8-4e5b-9664-b5d00dadbb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
